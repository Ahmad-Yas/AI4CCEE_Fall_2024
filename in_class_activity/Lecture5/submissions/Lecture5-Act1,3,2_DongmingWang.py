# -*- coding: utf-8 -*-
"""Untitled6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1F17dR1Y4usaViGbntbHVni3nhUdqi4Z6
"""

# prompt: Load data

import pandas as pd

# Load data from a CSV file
data = pd.read_csv('/content/Car_Speed.csv')

# prompt: Plot the data points on a scatter plot

import matplotlib.pyplot as plt

# Create a scatter plot
plt.scatter(data['Time'], data['WAVE-NE-Speed'])

# Add labels and title
plt.xlabel('Time')
plt.ylabel('WAVE-NE-Speed')
plt.title('Car WAVE-NE-Speed vs Time')

# Display the plot
plt.show()

# prompt: Split the dataset into training and testing sets

from sklearn.model_selection import train_test_split

# Assuming 'Time' is your feature and 'WAVE-NE-Speed' is your target
X = data[['Time']]
y = data['WAVE-NE-Speed']

# Split the data into training and testing sets (e.g., 80% training, 20% testing)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

df=pd.read_csv('/content/Car_Speed.csv')
print(df)

# prompt: Plot the data points on a scatter plot (time vs. speed)

import matplotlib.pyplot as plt

# Assuming 'Time' is your x-axis and 'WAVE-NE-Speed' is your y-axis
plt.scatter(df['Time'], df['WAVE-NE-Speed'])
plt.xlabel('Time')
plt.ylabel('WAVE-NE-Speed')
plt.title('Scatter Plot of Time vs. WAVE-NE-Speed')
plt.show()

# prompt: Split the dataset into training and testing sets

from sklearn.model_selection import train_test_split

# Assuming 'Time' is your feature and 'WAVE-NE-Speed' is your target
X = data[['Time']]
y = data['WAVE-NE-Speed']

# Split the data into training and testing sets (e.g., 80% training, 20% testing)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# prompt: Train a simple linear regression model using Python (scikit-learn)

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
import pandas as pd # Make sure pandas is imported

# Create a linear regression model
model = LinearRegression()

# Convert 'Time' column to numerical representation
# (e.g., Unix timestamp)
X_train['Time'] = pd.to_datetime(X_train['Time']).astype(int) / 10**9
X_test['Time'] = pd.to_datetime(X_test['Time']).astype(int) / 10**9

# *** Handle NaN values in y_train ***
y_train = y_train.dropna()

# *** Filter X_train to match the indices of y_train after dropping NaN ***
X_train = X_train.loc[y_train.index]

# Train the model on the training data
model.fit(X_train, y_train)

# ***Handle NaN values in y_test***
y_test = y_test.dropna()

# ***Filter X_test to match the indices of y_test after dropping NaN***
X_test = X_test.loc[y_test.index]

# Make predictions on the test data
y_pred = model.predict(X_test)

# Evaluate the model (e.g., using mean squared error)
mse = mean_squared_error(y_test, y_pred)
print(f"Mean Squared Error: {mse}")

# You can also print the coefficients and intercept of the model
print(f"Coefficients: {model.coef_}")
print(f"Intercept: {model.intercept_}")

# prompt: Use the testing data to evaluate the modelâ€™s performance

import matplotlib.pyplot as plt
from sklearn.metrics import r2_score

# Calculate R-squared (coefficient of determination)
r2 = r2_score(y_test, y_pred)
print(f"R-squared: {r2}")

# You can also calculate other metrics like Mean Absolute Error (MAE)
from sklearn.metrics import mean_absolute_error

mae = mean_absolute_error(y_test, y_pred)
print(f"Mean Absolute Error: {mae}")

# Visualize the predicted vs. actual values
plt.scatter(y_test, y_pred)
plt.xlabel("Actual WAVE-NE-Speed")
plt.ylabel("Predicted WAVE-NE-Speed")
plt.title("Actual vs. Predicted WAVE-NE-Speed")
plt.show()

# prompt: Calculate metrics like Mean Absolute Error (MAE) or Root Mean Squared Error
# (RMSE)

from sklearn.metrics import mean_absolute_error, mean_squared_error
import numpy as np

# Calculate MAE
mae = mean_absolute_error(y_test, y_pred)
print(f"Mean Absolute Error (MAE): {mae}")

# Calculate RMSE
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
print(f"Root Mean Squared Error (RMSE): {rmse}")

import pandas as pd

# Define the path to your CSV file
input_file_path = 'path_to_your_file.csv'
output_file_path = 'cleaned_crash_report.csv'

# Read the CSV file while skipping unnecessary rows
df = pd.read_csv('/content/ames_crashes.csv', skiprows=6)

# Clean up any unwanted columns (if needed)
# Here, we drop the empty columns that resulted from the original formatting
df = df.loc[:, ~df.columns.str.contains('^Unnamed')]

# Optionally, reset the index if needed
df.reset_index(drop=True, inplace=True)

# Save the cleaned DataFrame to a new CSV file
df.to_csv(output_file_path, index=False)

print(f"CSV file has been cleaned and saved as '{output_file_path}'.")

# prompt: Display the first few rows of the dataset using df.head()

print(df.head())

# prompt: Check for missing values and data types using df.info()

df.info()

# prompt: Create summary statistics using df.describe()

print(df.describe())

# prompt: Identify the target variable = crash severity

# Assuming 'Crash Severity' is the column name for crash severity in your dataset
target_variable = 'Crash Severity'

# prompt: Select relevant features for prediction : Time of day, driver age, vehicle type

# Select relevant features
features = ['City']

# Create a new DataFrame with only the selected features and target variable
selected_data = df[features + [target_variable]]

# Print the first few rows of the selected data
print(selected_data.head())

# prompt: Split the data into features (X) and target variable (y)

# Assuming 'Crash Severity' is your target variable
X = selected_data.drop('Crash Severity', axis=1)  # Features (all columns except the target)
y = selected_data['Crash Severity']  # Target variable

# prompt: Further split the data into training and testing sets (e.g., 80% training, 20% testing)

# Split the data into training and testing sets (e.g., 80% training, 20% testing)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# prompt: Use K-Means clustering to group Time points into clusters.

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans

# Assuming you want to cluster based on 'Time'
X_kmeans = data[['Time']]

# Convert 'Time' column to numerical representation
# (e.g., Unix timestamp)
X_kmeans['Time'] = pd.to_datetime(X_kmeans['Time']).astype(int) / 10**9


# Choose the number of clusters (you can experiment with different values)
n_clusters = 3

# Create a KMeans model
kmeans = KMeans(n_clusters=n_clusters, random_state=42)

# Fit the model to your data
kmeans.fit(X_kmeans)

# Get the cluster labels for each data point
cluster_labels = kmeans.labels_

# Add the cluster labels to your DataFrame
data['Cluster'] = cluster_labels

# Print the DataFrame with cluster labels
print(data)

# You can visualize the clusters (e.g., using a scatter plot)
plt.scatter(data['Time'], data['WAVE-NE-Speed'], c=data['Cluster'])
plt.xlabel('Time')
plt.ylabel('WAVE-NE-Speed')
plt.title('K-Means Clustering of Time Points')
plt.show()